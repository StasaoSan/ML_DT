{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Деревья решений и ансамбли\n",
    "\n",
    "Был выбран датасет отражающий загрязненность воздуха"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6ed8acdcde4c5579"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from build_data import get_processed_data\n",
    "from dt import DTclassifier_custom\n",
    "from dt_lib import DT_lib\n",
    "from start_tests import (\n",
    "    run_random_forest_experiment_custom,\n",
    "    run_random_forest_experiment_lib,\n",
    "    run_gradient_boosting_experiment_lib,\n",
    "    run_experiment_lib,\n",
    "    run_experiment_custom\n",
    ")\n",
    "from drawing_plots import plot_tree_depth, plot_accuracy"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e6366f59368cd1a8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Загрузка и предобработка данных:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ffb70ce0c7f0af5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    return pd.read_csv(file_path).dropna()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a9349474a5706ec2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    custom_mapping = {'Hazardous': 0, 'Poor': 1, 'Moderate': 2, 'Good': 3}\n",
    "    df['Air Quality'] = df['Air Quality'].map(custom_mapping)\n",
    "\n",
    "    y = df['Air Quality']\n",
    "    X = df.drop('Air Quality', axis=1)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    return X_scaled, y"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5da6383a9741d52"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Уменьшение объема выборки с использованием стратификации, разделение данных на тренировочную и валидационную выборки"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d6a383322570d26e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def stratified_sample(X, y, sample_size=1500, random_state=42):\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, train_size=sample_size, random_state=random_state)\n",
    "    for train_index, _ in sss.split(X, y):\n",
    "        X_sampled, y_sampled = X[train_index], y.iloc[train_index]\n",
    "    return X_sampled, y_sampled"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "625e4eb81061681b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def split_data(X, y, test_size=0.2, random_state=42):\n",
    "    return train_test_split(X, y, test_size=test_size, random_state=random_state, stratify=y)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a6636d15e218f671"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Общая функция подготовки и обработки данных"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "da478e3e4ef0a16d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_processed_data(file_path='pollution_dataset.csv', sample_size=1500):\n",
    "    df = load_data(file_path)\n",
    "    X, y = preprocess_data(df)\n",
    "\n",
    "    X_sampled, y_sampled = stratified_sample(X, y, sample_size=sample_size)\n",
    "\n",
    "    X_train, X_val, y_train, y_val = split_data(X_sampled, y_sampled)\n",
    "\n",
    "    return X_train, y_train.values, X_val, y_val.values"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "95c4dbbf3a589442"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Decision Tree Classifier Custom "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a1dd17a0125731b5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Узел дерева"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e89d5dac0b05a7ac"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class DecisionNode:\n",
    "    def __init__(self, feature_index=None, threshold=None, left=None, right=None, *, value=None):\n",
    "        self.feature_index = feature_index\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.value = value"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "19d557ba65a94675"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Реализация кастомного DT"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "74b1781798e66207"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class DTclassifier_custom:\n",
    "    def __init__(self, max_depth=None, criterion='gini', min_samples_split=4, min_samples_leaf=2):\n",
    "        self.max_depth = max_depth\n",
    "        self.criterion = criterion\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.root = None\n",
    "        self.n_classes_ = None\n",
    "        self.n_features_ = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.n_classes_ = len(np.unique(y))\n",
    "        self.n_features_ = X.shape[1]\n",
    "        self.root = self._grow_tree(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self._predict(inputs) for inputs in X])\n",
    "\n",
    "    def _gini(self, y):\n",
    "        m = len(y)\n",
    "        return 1.0 - sum((np.sum(y == c) / m) ** 2 for c in np.unique(y))\n",
    "\n",
    "    def _entropy(self, y):\n",
    "        m = len(y)\n",
    "        entropy = 0.0\n",
    "        for c in np.unique(y):\n",
    "            p = np.sum(y == c) / m\n",
    "            entropy -= p * np.log2(p) if p > 0 else 0\n",
    "        return entropy\n",
    "\n",
    "    def _best_split(self, X, y):\n",
    "        m, n = X.shape\n",
    "        if m <= 1:\n",
    "            return None, None\n",
    "\n",
    "        if self.criterion == 'gini':\n",
    "            parent_score = self._gini(y)\n",
    "        elif self.criterion == 'entropy':\n",
    "            parent_score = self._entropy(y)\n",
    "        else:\n",
    "            raise ValueError(\"Criterion must be 'gini' or 'entropy'\")\n",
    "\n",
    "        best_gain = 0.0\n",
    "        best_feature = None\n",
    "        best_threshold = None\n",
    "\n",
    "        for feature_index in range(n):\n",
    "            X_column = X[:, feature_index]\n",
    "            thresholds = np.unique(X_column)\n",
    "            for threshold in thresholds:\n",
    "                left_indices = X_column <= threshold\n",
    "                right_indices = X_column > threshold\n",
    "\n",
    "                if sum(left_indices) < self.min_samples_leaf or sum(right_indices) < self.min_samples_leaf:\n",
    "                    continue\n",
    "\n",
    "                y_left, y_right = y[left_indices], y[right_indices]\n",
    "\n",
    "                if self.criterion == 'gini':\n",
    "                    score_left = self._gini(y_left)\n",
    "                    score_right = self._gini(y_right)\n",
    "                else:\n",
    "                    score_left = self._entropy(y_left)\n",
    "                    score_right = self._entropy(y_right)\n",
    "\n",
    "                n_left, n_right = len(y_left), len(y_right)\n",
    "                gain = parent_score - (n_left / m) * score_left - (n_right / m) * score_right\n",
    "\n",
    "                if gain > best_gain:\n",
    "                    best_gain = gain\n",
    "                    best_feature = feature_index\n",
    "                    best_threshold = threshold\n",
    "\n",
    "        return best_feature, best_threshold\n",
    "\n",
    "    def _grow_tree(self, X, y, depth=0):\n",
    "        num_samples_per_class = [np.sum(y == i) for i in range(self.n_classes_)]\n",
    "        predicted_class = np.argmax(num_samples_per_class)\n",
    "        node = DecisionNode(value=predicted_class)\n",
    "\n",
    "        if (self.max_depth is not None and depth >= self.max_depth) or \\\n",
    "           len(np.unique(y)) == 1 or \\\n",
    "           len(y) < self.min_samples_split:\n",
    "            return node\n",
    "\n",
    "        feature_index, threshold = self._best_split(X, y)\n",
    "        if feature_index is None:\n",
    "            return node\n",
    "\n",
    "        indices_left = X[:, feature_index] <= threshold\n",
    "        X_left, y_left = X[indices_left], y[indices_left]\n",
    "        X_right, y_right = X[~indices_left], y[~indices_left]\n",
    "\n",
    "        node.feature_index = feature_index\n",
    "        node.threshold = threshold\n",
    "        node.left = self._grow_tree(X_left, y_left, depth + 1)\n",
    "        node.right = self._grow_tree(X_right, y_right, depth + 1)\n",
    "        node.value = None\n",
    "\n",
    "        return node\n",
    "\n",
    "    def _predict(self, inputs):\n",
    "        node = self.root\n",
    "        while node.value is None:\n",
    "            if inputs[node.feature_index] <= node.threshold:\n",
    "                node = node.left\n",
    "            else:\n",
    "                node = node.right\n",
    "        return node.value\n",
    "\n",
    "    def get_tree_depth(self):\n",
    "        return self._get_depth(self.root)\n",
    "\n",
    "    def _get_depth(self, node):\n",
    "        if node is None:\n",
    "            return 0\n",
    "        if node.value is not None:\n",
    "            return 1\n",
    "        return 1 + max(self._get_depth(node.left), self._get_depth(node.right))\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_accuracy(y_true, y_pred):\n",
    "        correct_predictions = np.sum(y_true == y_pred)\n",
    "        total_predictions = len(y_true)\n",
    "        accuracy = correct_predictions / total_predictions\n",
    "        return accuracy\n",
    "\n",
    "    def evaluate_with_min_samples_leaf(self, X_train, y_train, X_val, y_val):\n",
    "        hyperparam_name = \"min_samples_leaf\"\n",
    "        hyperparam_values = range(1, 21)\n",
    "        fixed_params = {\n",
    "            \"max_depth\": None,\n",
    "            \"criterion\": \"gini\",\n",
    "            \"min_samples_split\": 2\n",
    "        }\n",
    "        run_experiment_custom(hyperparam_name, hyperparam_values, X_train, y_train, X_val, y_val, fixed_params)\n",
    "\n",
    "    def evaluate_min_samples_split(self, X_train, y_train, X_val, y_val):\n",
    "        hyperparam_name = \"min_samples_split\"\n",
    "        hyperparam_values = range(2, 21)\n",
    "        fixed_params = {\n",
    "            \"max_depth\": None,\n",
    "            \"criterion\": \"gini\",\n",
    "            \"min_samples_leaf\": 1\n",
    "        }\n",
    "        run_experiment_custom(hyperparam_name, hyperparam_values, X_train, y_train, X_val, y_val, fixed_params)\n",
    "\n",
    "    def evaluate_with_criterion(self, X_train, y_train, X_val, y_val):\n",
    "        hyperparam_name = \"criterion\"\n",
    "        hyperparam_values = [\"gini\", \"entropy\"]\n",
    "        fixed_params = {\n",
    "            \"max_depth\": None,\n",
    "            \"min_samples_split\": 2,\n",
    "            \"min_samples_leaf\": 1\n",
    "        }\n",
    "        run_experiment_custom(hyperparam_name, hyperparam_values, X_train, y_train, X_val, y_val, fixed_params)\n",
    "\n",
    "    def evaluate_with_max_depth(self, X_train, y_train, X_val, y_val):\n",
    "        hyperparam_name = \"max_depth\"\n",
    "        hyperparam_values = list(range(1, 21)) + [None]\n",
    "        fixed_params = {\n",
    "            \"criterion\": \"gini\",\n",
    "            \"min_samples_split\": 2,\n",
    "            \"min_samples_leaf\": 1\n",
    "        }\n",
    "        run_experiment_custom(hyperparam_name, hyperparam_values, X_train, y_train, X_val, y_val, fixed_params, plot_type=\"accuracy\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "add3631f8b3169eb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Библиотечная версия DT"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c6cbaa5fab30d63e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class DT_lib:\n",
    "    def __init__(self, X_train, y_train, X_val, y_val):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_val = X_val\n",
    "        self.y_val = y_val\n",
    "\n",
    "    def evaluate_min_samples_leaf(self, min_samples_leaf_values=range(1, 21)):\n",
    "        hyperparam_name = 'min_samples_leaf'\n",
    "        fixed_params = {\n",
    "            'max_depth': None,\n",
    "            'criterion': 'entropy',\n",
    "            'min_samples_split': 2,\n",
    "            'random_state': 42\n",
    "        }\n",
    "        run_experiment_lib(hyperparam_name, min_samples_leaf_values, self.X_train, self.y_train, self.X_val, self.y_val, fixed_params)\n",
    "\n",
    "    def evaluate_min_samples_split(self, min_samples_split_values=range(2, 21)):\n",
    "        hyperparam_name = 'min_samples_split'\n",
    "        fixed_params = {\n",
    "            'max_depth': None,\n",
    "            'criterion': 'gini',\n",
    "            'min_samples_leaf': 1,\n",
    "            'random_state': 42\n",
    "        }\n",
    "        run_experiment_lib(hyperparam_name, min_samples_split_values, self.X_train, self.y_train, self.X_val, self.y_val, fixed_params)\n",
    "\n",
    "    def evaluate_max_leaf_nodes(self, max_leaf_nodes_values=None):\n",
    "        if max_leaf_nodes_values is None:\n",
    "            max_leaf_nodes_values = [None, 5, 10, 20, 50, 100]\n",
    "\n",
    "        hyperparam_name = 'max_leaf_nodes'\n",
    "        fixed_params = {\n",
    "            'max_depth': None,\n",
    "            'criterion': 'gini',\n",
    "            'min_samples_split': 2,\n",
    "            'min_samples_leaf': 1,\n",
    "            'random_state': 42\n",
    "        }\n",
    "        run_experiment_lib(hyperparam_name, max_leaf_nodes_values, self.X_train, self.y_train, self.X_val, self.y_val, fixed_params)\n",
    "\n",
    "    def evaluate_min_impurity_decrease(self, min_impurity_decrease_values=np.linspace(0.0, 0.15, 11)):\n",
    "        hyperparam_name = 'min_impurity_decrease'\n",
    "        fixed_params = {\n",
    "            'max_depth': None,\n",
    "            'criterion': 'gini',\n",
    "            'min_samples_split': 2,\n",
    "            'min_samples_leaf': 1,\n",
    "            'random_state': 42\n",
    "        }\n",
    "        run_experiment_lib(hyperparam_name, min_impurity_decrease_values, self.X_train, self.y_train, self.X_val, self.y_val, fixed_params)\n",
    "\n",
    "    def evaluate_ccp_alpha(self, ccp_alpha_values=np.linspace(0.0, 0.05, 30)):\n",
    "        hyperparam_name = 'ccp_alpha'\n",
    "        fixed_params = {\n",
    "            'max_depth': None,\n",
    "            'criterion': 'gini',\n",
    "            'min_samples_split': 2,\n",
    "            'min_samples_leaf': 1,\n",
    "            'random_state': 42\n",
    "        }\n",
    "        run_experiment_lib(hyperparam_name, ccp_alpha_values, self.X_train, self.y_train, self.X_val, self.y_val, fixed_params)\n",
    "\n",
    "    def evaluate_max_depth(self, max_depth_values=None):\n",
    "        if max_depth_values is None:\n",
    "            max_depth_values = list(range(1, 21)) + [None]\n",
    "\n",
    "        hyperparam_name = 'max_depth'\n",
    "        fixed_params = {\n",
    "            'criterion': 'gini',\n",
    "            'min_samples_split': 2,\n",
    "            'min_samples_leaf': 1,\n",
    "            'random_state': 42\n",
    "        }\n",
    "        run_experiment_lib(hyperparam_name, max_depth_values, self.X_train, self.y_train, self.X_val, self.y_val, fixed_params, plot_type=\"accuracy\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4175ebe2f8fce681"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Реализация алгоритма кастомного случайного леса"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8f01b8f2f50c7da9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class RandomForestClassifierCustom:\n",
    "    def __init__(self, n_estimators=100, max_features='sqrt', max_depth=None, bootstrap=True, random_state=None):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_features = max_features\n",
    "        self.max_depth = max_depth\n",
    "        self.bootstrap = bootstrap\n",
    "        self.random_state = random_state\n",
    "        self.trees = []\n",
    "        self.features_indices = []\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        np.random.seed(self.random_state)\n",
    "        self.trees = []\n",
    "        self.features_indices = []\n",
    "\n",
    "        n_samples, n_features = X_train.shape\n",
    "\n",
    "        if self.max_features == 'sqrt':\n",
    "            max_features = int(np.sqrt(n_features))\n",
    "        elif self.max_features == 'log2':\n",
    "            max_features = int(np.log2(n_features))\n",
    "        else:\n",
    "            max_features = n_features\n",
    "\n",
    "        for i in range(self.n_estimators):\n",
    "            if self.bootstrap:\n",
    "                indices = np.random.choice(n_samples, n_samples, replace=True)\n",
    "                X_sample = X_train[indices]\n",
    "                y_sample = y_train[indices]\n",
    "            else:\n",
    "                X_sample = X_train\n",
    "                y_sample = y_train\n",
    "\n",
    "            features_idx = np.random.choice(n_features, max_features, replace=False)\n",
    "            self.features_indices.append(features_idx)\n",
    "\n",
    "            tree = DTclassifier_custom(max_depth=self.max_depth)\n",
    "\n",
    "            tree.fit(X_sample[:, features_idx], y_sample)\n",
    "            self.trees.append(tree)\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for tree, features_idx in zip(self.trees, self.features_indices):\n",
    "            pred = tree.predict(X[:, features_idx])\n",
    "            predictions.append(pred)\n",
    "\n",
    "        predictions = np.array(predictions).T\n",
    "\n",
    "        y_pred = []\n",
    "        for preds in predictions:\n",
    "            y_pred.append(Counter(preds).most_common(1)[0][0])\n",
    "\n",
    "        return np.array(y_pred)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "68684ff6e894a255"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Взаимодействие с алгоритмами, перебор гиперпараметров, вызов функций построения графиков"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1e3473598f5ed65"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### dt custom"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3d1464cb66ebea7c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def run_experiment_custom(hyperparam_name, hyperparam_values, X_train, y_train, X_val, y_val, fixed_params, plot_type=\"tree_depth\"):\n",
    "    from dt import DTclassifier_custom\n",
    "\n",
    "    tree_depths = []\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    for value in hyperparam_values:\n",
    "        params = fixed_params.copy()\n",
    "        params[hyperparam_name] = value\n",
    "\n",
    "        custom_tree = DTclassifier_custom(**params)\n",
    "        custom_tree.fit(X_train, y_train)\n",
    "\n",
    "        depth = custom_tree.get_tree_depth()\n",
    "        tree_depths.append(depth)\n",
    "\n",
    "        y_train_pred = custom_tree.predict(X_train)\n",
    "        y_val_pred = custom_tree.predict(X_val)\n",
    "\n",
    "        train_accuracy = DTclassifier_custom.calculate_accuracy(y_train, y_train_pred)\n",
    "        val_accuracy = DTclassifier_custom.calculate_accuracy(y_val, y_val_pred)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "\n",
    "        print(f\"{hyperparam_name}: {value}, Tree Depth: {depth}, Train Acc: {train_accuracy:.4f}, Val Acc: {val_accuracy:.4f}\")\n",
    "    if plot_type == \"tree_depth\":\n",
    "        plot_tree_depth(hyperparam_name, hyperparam_values, tree_depths,  custom_realize=True)\n",
    "    elif plot_type == \"accuracy\":\n",
    "        plot_accuracy(hyperparam_name, hyperparam_values, train_accuracies, val_accuracies, custom_realize=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "42ee96668fbccc1b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### dt lib"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dc49d3f94aea936"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def run_experiment_lib(hyperparam_name, hyperparam_values, X_train, y_train, X_val, y_val, fixed_params, plot_type=\"tree_depth\"):\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "    tree_depths = []\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    for value in hyperparam_values:\n",
    "        params = fixed_params.copy()\n",
    "        params[hyperparam_name] = value\n",
    "\n",
    "        lib_tree = DecisionTreeClassifier(**params)\n",
    "        lib_tree.fit(X_train, y_train)\n",
    "\n",
    "        depth = lib_tree.get_depth()\n",
    "        tree_depths.append(depth)\n",
    "\n",
    "        train_accuracy = lib_tree.score(X_train, y_train)\n",
    "        val_accuracy = lib_tree.score(X_val, y_val)\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "\n",
    "        print(f\"{hyperparam_name}: {value}, Tree Depth: {depth}, Train Acc: {train_accuracy:.4f}, Val Acc: {val_accuracy:.4f}\")\n",
    "\n",
    "    if plot_type == \"tree_depth\":\n",
    "        plot_tree_depth(hyperparam_name, hyperparam_values, tree_depths, custom_realize=False)\n",
    "    elif plot_type == \"accuracy\":\n",
    "        plot_accuracy(hyperparam_name, hyperparam_values, train_accuracies, val_accuracies, custom_realize=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5027b604423a9eb3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### rf custom"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1648aa6ccbbdf8e7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def run_random_forest_experiment_custom(n_estimators_values, X_train, y_train, X_val, y_val):\n",
    "    from dt import DTclassifier_custom\n",
    "    from random_forest_custom import RandomForestClassifierCustom\n",
    "\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    for n_estimators in n_estimators_values:\n",
    "        rf_custom = RandomForestClassifierCustom(n_estimators=n_estimators, random_state=42)\n",
    "        rf_custom.fit(X_train, y_train)\n",
    "\n",
    "        y_train_pred = rf_custom.predict(X_train)\n",
    "        y_val_pred = rf_custom.predict(X_val)\n",
    "\n",
    "        train_accuracy = DTclassifier_custom.calculate_accuracy(y_train, y_train_pred)\n",
    "        val_accuracy = DTclassifier_custom.calculate_accuracy(y_val, y_val_pred)\n",
    "\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "\n",
    "        print(f\"n_estimators (rf_custom): {n_estimators}, Train Acc: {train_accuracy:.4f}, Val Acc: {val_accuracy:.4f}\")\n",
    "\n",
    "    plot_accuracy('n_estimators (rf)', n_estimators_values, train_accuracies, val_accuracies, custom_realize=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3c7398bc811ee30d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### rf lib"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "771bfe37f69fd3b8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def run_random_forest_experiment_lib(n_estimators_values, X_train, y_train, X_val, y_val):\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    for n_estimators in n_estimators_values:\n",
    "        rf = RandomForestClassifier(n_estimators=n_estimators, random_state=42)\n",
    "        rf.fit(X_train, y_train)\n",
    "\n",
    "        train_accuracy = rf.score(X_train, y_train)\n",
    "        val_accuracy = rf.score(X_val, y_val)\n",
    "\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "\n",
    "        print(f\"n_estimators (rf_lib): {n_estimators}, Train Acc: {train_accuracy:.4f}, Val Acc: {val_accuracy:.4f}\")\n",
    "\n",
    "    plot_accuracy('n_estimators (rf)', n_estimators_values, train_accuracies, val_accuracies, custom_realize=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "31aa267b9077011a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Использование алгоритма библиотечного бустинга, был выбран градиентный бустинг "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8537fe98c26aeee3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def run_gradient_boosting_experiment_lib(n_estimators_values, X_train, y_train, X_val, y_val):\n",
    "    from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "\n",
    "    for n_estimators in n_estimators_values:\n",
    "        gb = GradientBoostingClassifier(n_estimators=n_estimators, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "        gb.fit(X_train, y_train)\n",
    "\n",
    "        train_accuracy = gb.score(X_train, y_train)\n",
    "        val_accuracy = gb.score(X_val, y_val)\n",
    "\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "\n",
    "        print(f\"n_estimators (gradient boosting): {n_estimators}, Train Acc: {train_accuracy:.4f}, Val Acc: {val_accuracy:.4f}\")\n",
    "\n",
    "    plot_accuracy('n_estimators (gradient boosting)', n_estimators_values, train_accuracies, val_accuracies, custom_realize=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7e8584010c99c739"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Функции построения графиков, для глубины дерева и точности"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "46e79454bc006b74"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_tree_depth(hyperparam_name, hyperparam_values, tree_depths, custom_realize):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(hyperparam_values, tree_depths, marker='o')\n",
    "    plt.xlabel(hyperparam_name)\n",
    "    plt.ylabel('Tree Depth')\n",
    "    if custom_realize:\n",
    "        plt.title(f'Tree depth from: {hyperparam_name} (custom realization)')\n",
    "    else:\n",
    "        plt.title(f'Tree depth from: {hyperparam_name} (lib realization)')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def plot_accuracy(hyperparam_name, hyperparam_values, train_accuracies, val_accuracies, custom_realize):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(hyperparam_values, train_accuracies, marker='o', label='Train Accuracy')\n",
    "    plt.plot(hyperparam_values, val_accuracies, marker='s', label='Validation Accuracy')\n",
    "    plt.xlabel(hyperparam_name)\n",
    "    plt.ylabel('Accuracy')\n",
    "    if (custom_realize):\n",
    "        plt.title(f'Accuracy from: {hyperparam_name} (custom realization)')\n",
    "    else:\n",
    "        plt.title(f'Accuracy from: {hyperparam_name} (lib realization)')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "efe3cf173aef1608"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Main"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "25acaacaa381ab80"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def main():\n",
    "    X_train_np, y_train_np, X_val_np, y_val_np = get_processed_data()\n",
    "\n",
    "    DTcustom = DTclassifier_custom(max_depth=None, criterion='entropy', min_samples_split=2, min_samples_leaf=1)\n",
    "\n",
    "    DTcustom.evaluate_with_min_samples_leaf(X_train_np, y_train_np, X_val_np, y_val_np)\n",
    "    DTcustom.evaluate_min_samples_split(X_train_np, y_train_np, X_val_np, y_val_np)\n",
    "    DTcustom.evaluate_with_criterion(X_train_np, y_train_np, X_val_np, y_val_np)\n",
    "    DTcustom.evaluate_with_max_depth(X_train_np, y_train_np, X_val_np, y_val_np)\n",
    "\n",
    "    DTlib = DT_lib(X_train_np, y_train_np, X_val_np, y_val_np)\n",
    "    DTlib.evaluate_min_samples_split()\n",
    "    DTlib.evaluate_min_samples_leaf()\n",
    "    DTlib.evaluate_min_impurity_decrease()\n",
    "    DTlib.evaluate_max_leaf_nodes()\n",
    "    DTlib.evaluate_ccp_alpha()\n",
    "    DTlib.evaluate_max_depth()\n",
    "\n",
    "    n_estimators_values = [5, 10, 20, 50, 100, 150]\n",
    "    run_random_forest_experiment_custom(n_estimators_values, X_train_np, y_train_np, X_val_np, y_val_np)\n",
    "    run_random_forest_experiment_lib(n_estimators_values, X_train_np, y_train_np, X_val_np, y_val_np)\n",
    "\n",
    "    run_gradient_boosting_experiment_lib(n_estimators_values, X_train_np, y_train_np, X_val_np, y_val_np)\n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e0313099df42b5b2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
